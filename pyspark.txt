from pyspark.sql import DataFrame
from pyspark.sql import functions as F

def get_product_category_pairs(products_df: DataFrame, 
                              categories_df: DataFrame, 
                              product_category_links_df: DataFrame) -> DataFrame:
    """
    Возвращает датафрейм со всеми парами "Имя продукта - Имя категории" 
    и продуктами без категорий.
    
    Args:
        products_df: DataFrame с продуктами (ожидаются колонки: product_id, product_name)
        categories_df: DataFrame с категориями (ожидаются колонки: category_id, category_name)
        product_category_links_df: DataFrame со связями (ожидаются колонки: product_id, category_id)
    
    Returns:
        DataFrame с колонками: product_name, category_name
        где category_name может быть null для продуктов без категорий
    """
    
    # 1. Левое соединение продуктов со связями
    products_with_links = products_df.alias("p").join(
        product_category_links_df.alias("pcl"),
        F.col("p.product_id") == F.col("pcl.product_id"),
        "left"
    )
    
    # 2. Левое соединение результата с категориями
    result = products_with_links.join(
        categories_df.alias("c"),
        F.col("pcl.category_id") == F.col("c.category_id"),
        "left"
    ).select(
        F.col("p.product_name").alias("product_name"),
        F.col("c.category_name").alias("category_name")
    )
    
    return result


# Альтернативный вариант с более явным разделением на продукты с категориями и без:
def get_product_category_pairs_v2(products_df: DataFrame, 
                                 categories_df: DataFrame, 
                                 product_category_links_df: DataFrame) -> DataFrame:
    """
    Альтернативная реализация с явным объединением продуктов с категориями и без категорий.
    """
    
    # Продукты с категориями
    products_with_categories = products_df.alias("p") \
        .join(product_category_links_df.alias("pcl"), 
              F.col("p.product_id") == F.col("pcl.product_id"), "inner") \
        .join(categories_df.alias("c"), 
              F.col("pcl.category_id") == F.col("c.category_id"), "inner") \
        .select(F.col("p.product_name").alias("product_name"),
                F.col("c.category_name").alias("category_name"))
    
    # Продукты без категорий
    products_without_categories = products_df.alias("p") \
        .join(product_category_links_df.alias("pcl"), 
              F.col("p.product_id") == F.col("pcl.product_id"), "left_anti") \
        .select(F.col("p.product_name").alias("product_name"),
                F.lit(None).cast("string").alias("category_name"))
    
    # Объединение результатов
    result = products_with_categories.union(products_without_categories)
    
    return result


# Пример использования:
if __name__ == "__main__":
    from pyspark.sql import SparkSession
    
    spark = SparkSession.builder.appName("ProductCategoryExample").getOrCreate()
    
    # Пример данных
    products_data = [
        (1, "Телефон iPhone"),
        (2, "Ноутбук MacBook"),
        (3, "Мышь беспроводная"),
        (4, "Книга Python")
    ]
    
    categories_data = [
        (1, "Электроника"),
        (2, "Компьютеры"),
        (3, "Аксессуары"),
        (4, "Книги")
    ]
    
    links_data = [
        (1, 1),  # iPhone -> Электроника
        (2, 1),  # MacBook -> Электроника
        (2, 2),  # MacBook -> Компьютеры
        (3, 3),  # Мышь -> Аксессуары
        # Книга Python (id=4) не имеет связей с категориями
    ]
    
    # Создание датафреймов
    products_df = spark.createDataFrame(products_data, ["product_id", "product_name"])
    categories_df = spark.createDataFrame(categories_data, ["category_id", "category_name"])
    links_df = spark.createDataFrame(links_data, ["product_id", "category_id"])
    
    # Вызов метода
    result = get_product_category_pairs(products_df, categories_df, links_df)
    
    # Показать результат
    result.show(truncate=False)